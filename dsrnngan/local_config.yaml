LOCAL:
    data_paths: "BLUE_PEBBLE"  # "ECMWF", "AOPP", "BLUE_PEBBLE"; uses appropriate entries in data_paths.yaml
    gpu_mem_incr: True  # allocate GPU memory incrementally; use True at AOPP (and False at ECMWF?)
    use_gpu: True  # use GPU _if possible_ (False guarantees that it will not be used).  this is done by setting or unsetting the CUDA_VISIBLE_DEVICES environment variable
    disable_tf32: False  # whether to explicitly disable the use of TensorFloat-32 calculations when running on the GPU

MODEL:
    mode: "GAN" # choices 'det' 'GAN' 'VAEGAN'
    problem_type: "normal" # choices 'normal' 'superresolution'
    downsample: False
    architecture: "forceconv" # choices 'normal' 'forceconv'
    padding: "reflect"  # convolution padding: 'same', 'reflect', or 'symmetric'
    log_folder: "/user/work/uz22147/logs/cgan"

DATA:
    fcst_data_source: "ifs"
    obs_data_source: "imerg"
    input_channels: 20 # e.g. Number of variables from forecast data
    constant_fields: 2
    input_image_width: 264 # Assumes a square image
    num_samples: 320000
    num_samples_per_image: 1
    normalise: True
    num_classes: 4 # Number of bins to split data into
    min_latitude: -11.95
    max_latitude: 15.05
    latitude_step_size: 0.1
    min_longitude: 25.05
    max_longitude: 51.45
    longitude_step_size: 0.1
    class_bin_boundaries: [0.045, 0.067, 0.093] # These are the quartile boundaries for the training data

DOWNSCALING:
    downscaling_factor: 1  # increase in image size in each dimension
    steps: [1]  # list of integers that multiply to the downscaling factor; the generator will use UpSampling2D layers of these sizes, alternating with residual blocks.

GENERATOR:
    filters_gen: 64
    noise_channels: 4 # used for GAN
    latent_variables: 1 # used for VAEGAN
    learning_rate_gen: 1e-5

DISCRIMINATOR:
    filters_disc: 256
    learning_rate_disc: 1e-5

TRAIN:
    training_range: ['201603', '201802'] # Start and end of training period, in YYYYMM format
    normalisation_year: 2017
    training_weights: [0.25, 0.25, 0.25, 0.25]
    num_epochs: 5
    steps_per_checkpoint: 3200
    batch_size: 2  # can use 400x16 without CL, or 3200x2 with CL
    kl_weight: 1e-8  # used for VAEGAN
    ensemble_size: 8  # size of pred ensemble for content loss
    CL_type: "ensmeanMSE" # type of content loss to use: 'CRPS', 'CRPS_phys', 'ensmeanMSE', 'ensmeanMSE_phys'
    content_loss_weight: 1000.0
    # img_chunk_width: 200

VAL:
    val_range: ['201806', '201905'] # cannot pass a list if using create_fixed_dataset
    val_size: 100
    ensemble_size: 20
