{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os, sys\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colorbar, colors, gridspec\n",
    "from metpy import plots as metpy_plots\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "\n",
    "HOME = Path(os.getcwd()).parents[0]\n",
    "\n",
    "sys.path.insert(1, str(HOME))\n",
    "\n",
    "from dsrnngan.plots import plot_precip, plot_contourf\n",
    "from dsrnngan.data import denormalise, DEFAULT_LATITUDE_RANGE, DEFAULT_LONGITUDE_RANGE\n",
    "from dsrnngan import data\n",
    "from dsrnngan.noise import NoiseGenerator\n",
    "from dsrnngan.rapsd import plot_spectrum1d, rapsd\n",
    "from dsrnngan.thresholded_ranks import findthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_number = 230400\n",
    "model_number = 160000\n",
    "model_type = 'basic'\n",
    "\n",
    "log_folders = {'basic': '/user/work/uz22147/logs/cgan/d9b8e8059631e76f/n1000_201806-201905_e50',\n",
    "               'full_image': '/user/work/uz22147/logs/cgan/43ae7be47e9a182e_full_image/n1000_201806-201905_e50',\n",
    "               'cropped': '/user/work/uz22147/logs/cgan/43ae7be47e9a182e/n3000_201806-201905_e10'}\n",
    "\n",
    "log_folder = log_folders[model_type]\n",
    "with open(os.path.join(log_folder, f'arrays-{model_number}.pkl'), 'rb') as ifh:\n",
    "    arrays = pickle.load(ifh)\n",
    "    \n",
    "truth_array = arrays['truth']\n",
    "samples_gen_array = arrays['samples_gen']\n",
    "fcst_array = arrays['fcst_array']\n",
    "ensmean_array = np.mean(arrays['samples_gen'], axis=-1)\n",
    "dates = [d[0] for d in arrays['dates']]\n",
    "hours = [h[0] for h in arrays['hours']]\n",
    "\n",
    "assert len(set(list(zip(dates, hours)))) == fcst_array.shape[0], \"Degenerate date/hour combinations\"\n",
    "(n_samples, width, height, ensemble_size) = samples_gen_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsrnngan.utils import load_yaml_file\n",
    "# Get lat/lon range from log folder\n",
    "base_folder = '/'.join(log_folder.split('/')[:-1])\n",
    "config = load_yaml_file(os.path.join(base_folder, 'setup_params.yaml'))\n",
    "\n",
    "# Locations\n",
    "min_latitude = config['DATA']['min_latitude']\n",
    "max_latitude = config['DATA']['max_latitude']\n",
    "latitude_step_size = config['DATA']['latitude_step_size']\n",
    "min_longitude = config['DATA']['min_longitude']\n",
    "max_longitude = config['DATA']['max_longitude']\n",
    "longitude_step_size = config['DATA']['longitude_step_size']\n",
    "latitude_range=np.arange(min_latitude, max_latitude, latitude_step_size)\n",
    "longitude_range=np.arange(min_longitude, max_longitude, longitude_step_size)\n",
    "\n",
    "\n",
    "# Quantiles\n",
    "step_size = 0.001\n",
    "range_dict = {0: {'start': 0.1, 'stop': 1, 'interval': 0.1, 'marker': '+', 'marker_size': 32},\n",
    "              1: {'start': 1, 'stop': 10, 'interval': 1, 'marker': '+', 'marker_size': 256},\n",
    "              2: {'start': 10, 'stop': 80, 'interval':10, 'marker': '+', 'marker_size': 512},\n",
    "              3: {'start': 80, 'stop': 99.1, 'interval': 1, 'marker': '+', 'marker_size': 256},\n",
    "              4: {'start': 99.1, 'stop': 99.91, 'interval': 0.1, 'marker': '+', 'marker_size': 128},\n",
    "              5: {'start': 99.9, 'stop': 99.99, 'interval': 0.01, 'marker': '+', 'marker_size': 32 },\n",
    "              6: {'start': 99.99, 'stop': 99.999, 'interval': 0.001, 'marker': '+', 'marker_size': 10}}\n",
    "                  \n",
    "percentiles_list= [np.arange(item['start'], item['stop'], item['interval']) for item in range_dict.values()]\n",
    "percentiles=np.concatenate(percentiles_list)\n",
    "quantile_locs = [np.round(item / 100.0, 6) for item in percentiles]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "imerg_train_data = []\n",
    "ifs_train_data = []\n",
    "ifs_dates = []\n",
    "imerg_dates = []\n",
    "\n",
    "for year in tqdm([2016, 2017]):\n",
    "    for month in range(1,13):\n",
    "\n",
    "        imerg_ds = xr.open_dataarray(f'/user/home/uz22147/repos/rainfall_data/daily_imerg_rainfall_{month}_{year}.nc')\n",
    "\n",
    "        imerg_data = imerg_ds.sel(lat=latitude_range, method='nearest').sel(lon=longitude_range, method='nearest').values\n",
    "        \n",
    "        imerg_dates += [d.astype('M8[D]').astype('O') for d in imerg_ds.time.values]\n",
    "\n",
    "        for t in range(imerg_data.shape[0]):\n",
    "            \n",
    "            snapshot = imerg_data[t, :, :]\n",
    "            \n",
    "            imerg_train_data.append(snapshot)\n",
    "        \n",
    "        try:\n",
    "            ifs_ds = xr.open_dataarray(f'/user/home/uz22147/repos/rainfall_data/daily_ifs_rainfall_{month}_{year}.nc')\n",
    "\n",
    "            ifs_data = ifs_ds.sel(lat=latitude_range, method='nearest').sel(lon=longitude_range, method='nearest').values\n",
    "\n",
    "            for t in range(ifs_data.shape[0]):\n",
    "                \n",
    "                snapshot = ifs_data[t, :, :]\n",
    "                \n",
    "                ifs_train_data.append(snapshot)\n",
    "            ifs_dates += [d.astype('M8[D]').astype('O') for d in ifs_ds.time.values]\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "imerg_train_data = np.stack(imerg_train_data, axis = 0)\n",
    "ifs_train_data = np.stack(ifs_train_data, axis = 0)\n",
    "\n",
    "# Make dates consistent\n",
    "overlapping_dates = np.array(sorted(set(ifs_dates).intersection(imerg_dates)))\n",
    "\n",
    "imerg_overlapping_date_ix = [n for n, item in enumerate(imerg_dates) if item in overlapping_dates]\n",
    "ifs_overlapping_date_ix = [n for n, item in enumerate(ifs_dates) if item in overlapping_dates]\n",
    "\n",
    "imerg_train_data = imerg_train_data[imerg_overlapping_date_ix, :, :]\n",
    "ifs_train_data = ifs_train_data[ifs_overlapping_date_ix , :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifs_training_quantiles = np.quantile(ifs_train_data.flatten(), quantile_locs)\n",
    "imerg_training_quantiles = np.quantile(imerg_train_data.flatten(), quantile_locs)\n",
    "\n",
    "ifs_test_quantiles = np.quantile(fcst_array.flatten(), quantile_locs)\n",
    "imerg_test_quantiles = np.quantile(truth_array.flatten(), quantile_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(imerg_test_quantiles, ifs_test_quantiles)\n",
    "plt.plot(imerg_test_quantiles, imerg_test_quantiles, 'o--')\n",
    "\n",
    "# plt.plot(imerg_training_quantiles, ifs_training_quantiles)\n",
    "plt.plot(imerg_training_quantiles, ifs_training_quantiles, '--')\n",
    "\n",
    "plt.plot(imerg_test_quantiles, np.interp(ifs_test_quantiles, ifs_training_quantiles, imerg_training_quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsrnngan.benchmarks import get_quantile_areas, get_quantiles_by_area, get_quantile_mapped_forecast\n",
    "\n",
    "month_ranges = [[1,2], [3,4,5], [6,7,8,9], [10,11,12]]\n",
    "quantile_threshold = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify best threshold and train on all the data\n",
    "quantile_areas = get_quantile_areas(list(overlapping_dates), month_ranges, latitude_range, longitude_range)\n",
    "quantiles_by_area = get_quantiles_by_area(quantile_areas, fcst_data=ifs_train_data, obs_data=imerg_train_data, \n",
    "                                          quantile_locs=quantile_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_corrected = get_quantile_mapped_forecast(fcst=fcst_array, dates=dates, \n",
    "                                              hours=hours, month_ranges=month_ranges, \n",
    "                                              quantile_areas=quantile_areas, \n",
    "                                              quantiles_by_area=quantiles_by_area)\n",
    "                                            #   quantile_threshold=0.99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/user/home/uz22147/repos/downscaling-cgan/mae_vals.pkl', 'rb') as ifh:\n",
    "\n",
    "    mae_vals = pickle.load(ifh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [item[1] for item in mae_vals['mae_95']]\n",
    "x = [item[0] for item in mae_vals['mae_95']] \n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "(q_99pt9, q_99pt99) = np.quantile(truth_array, [0.999, 0.9999])\n",
    "fitting_data = np.random.choice(truth_array.flatten(), size=int(4e6), replace=False)\n",
    "\n",
    "# fit_alpha, fit_loc, fit_beta=gamma.fit(fitting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Fitting using moments; perhaps would be better using mse distance but it is super slow\n",
    "def get_gamma_parameters(data):\n",
    "    mean = np.mean(data)\n",
    "    variance = np.var(data)\n",
    "    \n",
    "    shape = mean*mean/variance\n",
    "    scale = variance/mean\n",
    "    \n",
    "    return shape, scale\n",
    "\n",
    "def get_lognormal_parameters(data):\n",
    "    \n",
    "    e_x = np.mean(data)\n",
    "    var_x = np.var(data)\n",
    "    \n",
    "    var = np.log(1 + var_x / e_x**2)\n",
    "    mu = np.log( e_x * np.exp(-0.5*var))\n",
    "    \n",
    "    return mu, var\n",
    "\n",
    "# force integer values to get integer sample\n",
    "shape, scale = get_gamma_parameters(truth_array)\n",
    "gamma_sample_data = np.random.gamma(shape=shape, scale=scale, size=truth_array.size)\n",
    "\n",
    "lognormal_mean, lognormal_variance = get_lognormal_parameters(truth_array)\n",
    "lognormal_sample_data = np.random.lognormal(mean=lognormal_mean, sigma=np.sqrt(lognormal_variance), size=truth_array.size)\n",
    "# sample_data = [i for i in gamma_random_sample(mean, variance, int(4e6))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "ax.hist(truth_array.flatten(), bins=np.arange(0,300,4), histtype= 'step', label='original', density=False)\n",
    "ax.hist(lognormal_sample_data, histtype= 'step', label='lognormal', bins=np.arange(0,300,4), density=False)\n",
    "ax.hist(gamma_sample_data, histtype= 'step', label='gamma', bins=np.arange(0,300,4), density=False)\n",
    "\n",
    "\n",
    "ax.vlines(q_99pt99, 0, 10**8, linestyles='--')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
